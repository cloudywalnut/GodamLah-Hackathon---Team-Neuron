{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paynet Project Trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature 1 (Email Name Score): Randomly generated continuous values between 0 and 1.\n",
    "\n",
    "Feature 2 (State - Deliverable or Not): Randomly assigned binary values (0 or 1).\n",
    "\n",
    "Feature 3 (SMTP Check): Randomly assigned binary values (0 or 1).\n",
    "\n",
    "Feature 4 (MX Found): Randomly assigned binary values (0 or 1).\n",
    "\n",
    "Feature 5 (Disposable): Randomly assigned binary values (0 or 1).\n",
    "\n",
    "Label (y_train): Random binary values (0 or 1) representing whether the email is legit or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to figure out these relationships, and I would like you to generate synthetic data while keeping this in mind: If Feature 1 has a higher score, it will have a positive impact on our prediction towards 1. Similarly, if Features 2 to 4 have higher values (1), they will also positively impact the result towards 1. However, if the last feature (Feature 5) is 1, it will have a negative impact on our prediction towards 1. Keeping these rules in mind, please generate a set of data similar to the example I provided previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 5)\n",
      "(200,)\n",
      "Epoch 1/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.7257\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6496 \n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6181 \n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5953 \n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5701 \n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5400 \n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5078 \n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4714 \n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4368 \n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4027 \n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3692 \n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3412 \n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3185 \n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3017 \n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2863 \n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2750 \n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2657 \n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2548 \n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2496 \n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2399 \n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2367 \n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2282 \n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2250 \n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2170 \n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2124 \n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2069 \n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2018 \n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1956 \n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1933 \n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1866 \n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1823 \n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1788 \n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1737 \n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1687 \n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1680 \n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1613 \n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1578 \n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1534 \n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1530 \n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1474 \n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1442 \n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1403 \n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1369 \n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1370 \n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1327 \n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1285 \n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1270 \n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1223 \n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1210 \n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1194 \n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1165 \n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1121 \n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1129 \n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1068 \n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1085 \n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1020 \n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.1051 \n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0978 \n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0991 \n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0960 \n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0939 \n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0943 \n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0897 \n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0898 \n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0879 \n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0874 \n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0841 \n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0838 \n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0822 \n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0814 \n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0793 \n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0787 \n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0771 \n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0767 \n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0761 \n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0744 \n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0733 \n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0722 \n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0734 \n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0695 \n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0706 \n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0690 \n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0686 \n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0673 \n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0673 \n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0664 \n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0657 \n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0647 \n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0642 \n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0641 \n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0631 \n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0622 \n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0618 \n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0617 \n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0609 \n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0601 \n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0601 \n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0589 \n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0593 \n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0584 \n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "[0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0\n",
      " 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0\n",
      " 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1\n",
      " 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1\n",
      " 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0]\n",
      "[[9.2325802e-04]\n",
      " [9.6729499e-01]\n",
      " [4.0784103e-01]\n",
      " [7.9198577e-02]\n",
      " [9.9999547e-01]\n",
      " [9.9976403e-01]\n",
      " [1.5427378e-09]\n",
      " [9.9683893e-01]\n",
      " [2.1318390e-11]\n",
      " [9.9971062e-01]\n",
      " [9.9999905e-01]\n",
      " [4.0189094e-05]\n",
      " [9.9977875e-01]\n",
      " [1.0992493e-07]\n",
      " [9.9969256e-01]\n",
      " [6.8176168e-01]\n",
      " [2.5572220e-04]\n",
      " [9.9999970e-01]\n",
      " [1.0403278e-02]\n",
      " [1.8742868e-07]\n",
      " [9.2325802e-04]\n",
      " [9.6729499e-01]\n",
      " [4.0784103e-01]\n",
      " [7.9198577e-02]\n",
      " [9.9999547e-01]\n",
      " [9.9976403e-01]\n",
      " [1.5427378e-09]\n",
      " [9.9683893e-01]\n",
      " [2.1318390e-11]\n",
      " [9.9971062e-01]\n",
      " [9.9999905e-01]\n",
      " [4.0189094e-05]\n",
      " [9.9977875e-01]\n",
      " [1.0992493e-07]\n",
      " [9.9969256e-01]\n",
      " [6.8176168e-01]\n",
      " [2.5572220e-04]\n",
      " [9.9999970e-01]\n",
      " [1.0403278e-02]\n",
      " [1.8742868e-07]\n",
      " [9.2325802e-04]\n",
      " [9.6729499e-01]\n",
      " [4.0784103e-01]\n",
      " [7.9198577e-02]\n",
      " [9.9999547e-01]\n",
      " [9.9976403e-01]\n",
      " [1.5427378e-09]\n",
      " [9.9683893e-01]\n",
      " [2.1318390e-11]\n",
      " [9.9971062e-01]\n",
      " [9.9999905e-01]\n",
      " [4.0189094e-05]\n",
      " [9.9977875e-01]\n",
      " [1.0992493e-07]\n",
      " [9.9969256e-01]\n",
      " [6.8176168e-01]\n",
      " [2.5572220e-04]\n",
      " [9.9999970e-01]\n",
      " [1.0403278e-02]\n",
      " [1.8742868e-07]\n",
      " [9.2325802e-04]\n",
      " [9.6729499e-01]\n",
      " [4.0784073e-01]\n",
      " [7.9198562e-02]\n",
      " [9.9999547e-01]\n",
      " [9.9976403e-01]\n",
      " [1.5427378e-09]\n",
      " [9.9683893e-01]\n",
      " [2.1318390e-11]\n",
      " [9.9971062e-01]\n",
      " [9.9999905e-01]\n",
      " [4.0189094e-05]\n",
      " [9.9977875e-01]\n",
      " [1.0992493e-07]\n",
      " [9.9969256e-01]\n",
      " [6.8176168e-01]\n",
      " [2.5572220e-04]\n",
      " [9.9999970e-01]\n",
      " [1.0403278e-02]\n",
      " [1.8742868e-07]\n",
      " [9.2325802e-04]\n",
      " [9.6729499e-01]\n",
      " [4.0784103e-01]\n",
      " [7.9198577e-02]\n",
      " [9.9999547e-01]\n",
      " [9.9976403e-01]\n",
      " [1.5427378e-09]\n",
      " [9.9683893e-01]\n",
      " [2.1318390e-11]\n",
      " [9.9971062e-01]\n",
      " [9.9999905e-01]\n",
      " [4.0189094e-05]\n",
      " [9.9977875e-01]\n",
      " [1.0992493e-07]\n",
      " [9.9969256e-01]\n",
      " [6.8176150e-01]\n",
      " [2.5572220e-04]\n",
      " [9.9999970e-01]\n",
      " [1.0403278e-02]\n",
      " [1.8742868e-07]\n",
      " [9.2325802e-04]\n",
      " [9.6729499e-01]\n",
      " [4.0784103e-01]\n",
      " [7.9198577e-02]\n",
      " [9.9999547e-01]\n",
      " [9.9976403e-01]\n",
      " [1.5427378e-09]\n",
      " [9.9683893e-01]\n",
      " [2.1318390e-11]\n",
      " [9.9971062e-01]\n",
      " [9.9999905e-01]\n",
      " [4.0189094e-05]\n",
      " [9.9977875e-01]\n",
      " [1.0992493e-07]\n",
      " [9.9969256e-01]\n",
      " [6.8176168e-01]\n",
      " [2.5572220e-04]\n",
      " [9.9999970e-01]\n",
      " [1.0403278e-02]\n",
      " [1.8742868e-07]\n",
      " [9.2325802e-04]\n",
      " [9.6729499e-01]\n",
      " [4.0784103e-01]\n",
      " [7.9198577e-02]\n",
      " [9.9999547e-01]\n",
      " [9.9976403e-01]\n",
      " [1.5427348e-09]\n",
      " [9.9683893e-01]\n",
      " [2.1318390e-11]\n",
      " [9.9971062e-01]\n",
      " [9.9999905e-01]\n",
      " [4.0189094e-05]\n",
      " [9.9977875e-01]\n",
      " [1.0992493e-07]\n",
      " [9.9969256e-01]\n",
      " [6.8176168e-01]\n",
      " [2.5572220e-04]\n",
      " [9.9999970e-01]\n",
      " [1.0403278e-02]\n",
      " [1.8742868e-07]\n",
      " [9.2325802e-04]\n",
      " [9.6729499e-01]\n",
      " [4.0784103e-01]\n",
      " [7.9198577e-02]\n",
      " [9.9999547e-01]\n",
      " [9.9976403e-01]\n",
      " [1.5427378e-09]\n",
      " [9.9683893e-01]\n",
      " [2.1318390e-11]\n",
      " [9.9971062e-01]\n",
      " [9.9999905e-01]\n",
      " [4.0189094e-05]\n",
      " [9.9977875e-01]\n",
      " [1.0992493e-07]\n",
      " [9.9969256e-01]\n",
      " [6.8176168e-01]\n",
      " [2.5572220e-04]\n",
      " [9.9999970e-01]\n",
      " [1.0403278e-02]\n",
      " [1.8742904e-07]\n",
      " [9.2325802e-04]\n",
      " [9.6729499e-01]\n",
      " [4.0784103e-01]\n",
      " [7.9198577e-02]\n",
      " [9.9999547e-01]\n",
      " [9.9976403e-01]\n",
      " [1.5427378e-09]\n",
      " [9.9683893e-01]\n",
      " [2.1318390e-11]\n",
      " [9.9971062e-01]\n",
      " [9.9999905e-01]\n",
      " [4.0189094e-05]\n",
      " [9.9977875e-01]\n",
      " [1.0992493e-07]\n",
      " [9.9969256e-01]\n",
      " [6.8176168e-01]\n",
      " [2.5572220e-04]\n",
      " [9.9999970e-01]\n",
      " [1.0403278e-02]\n",
      " [1.8742868e-07]\n",
      " [9.2325802e-04]\n",
      " [9.6729499e-01]\n",
      " [4.0784103e-01]\n",
      " [7.9198577e-02]\n",
      " [9.9999547e-01]\n",
      " [9.9976403e-01]\n",
      " [1.5427378e-09]\n",
      " [9.9683893e-01]\n",
      " [2.1318390e-11]\n",
      " [9.9971062e-01]\n",
      " [9.9999905e-01]\n",
      " [4.0189094e-05]\n",
      " [9.9977875e-01]\n",
      " [1.0992493e-07]\n",
      " [9.9969256e-01]\n",
      " [6.8176168e-01]\n",
      " [2.5572220e-04]\n",
      " [9.9999970e-01]\n",
      " [1.0403278e-02]\n",
      " [1.8742904e-07]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# Manually generated synthetic data for X_train and y_train\n",
    "x_train = np.array([\n",
    "    [0.9, 0, 0, 0, 1], [0.75, 1, 0, 1, 0], [0.40, 1, 1, 1, 0], [0.59, 1, 0, 1, 0], [0.93, 1, 1, 0, 0],\n",
    "    [0.72, 1, 1, 1, 0], [0.45, 0, 1, 0, 1], [0.82, 1, 0, 1, 0], [0.38, 0, 1, 0, 1], [0.95, 1, 0, 1, 0],\n",
    "    [0.8, 1, 1, 1, 1], [0.3, 1, 1, 0, 1], [0.75, 1, 0, 1, 1], [0.4, 1, 0, 1, 1], [0.6, 1, 1, 0, 1],\n",
    "    [0.42, 1, 1, 1, 0], [0.3, 1, 1, 1, 1], [0.8, 1, 1, 0, 1], [0.46,1,1,0,0], [0.3, 0, 1, 1, 0]\n",
    "])\n",
    "\n",
    "# Labels for each example (legit or not legit)\n",
    "y_train = np.array([\n",
    "    0, 1, 0, 0, 1,\n",
    "    1, 0, 1, 0, 1,\n",
    "    1, 0, 1, 0, 1,\n",
    "    1, 0, 1, 0, 0\n",
    "])\n",
    "\n",
    "x_train = np.tile(x_train, [10,1])\n",
    "y_train = np.tile(y_train, 10)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(10, activation = 'relu', name = 'layer1'),\n",
    "    Dense(5, activation = 'relu', name = 'layer2'),\n",
    "    Dense(1, activation= 'sigmoid', name = 'layer3')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs = 100\n",
    ")\n",
    "\n",
    "y_hat = model.predict(x_train)\n",
    "print(y_train)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0\n",
      " 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0\n",
      " 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1\n",
      " 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1\n",
      " 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0]\n",
      "[0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0\n",
      " 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0\n",
      " 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1\n",
      " 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 1\n",
      " 1 0 1 0 1 1 0 1 0 1 1 0 1 0 0]\n",
      "The Accuracy is: 1.0\n"
     ]
    }
   ],
   "source": [
    "prediction = np.where(y_hat>0.6, 1, 0)\n",
    "prediction = prediction.reshape(-1)\n",
    "print(y_train)\n",
    "print(prediction)\n",
    "count = 0\n",
    "for i in range(len(y_train)):\n",
    "    if prediction[i] == y_train[i]:\n",
    "        count +=1\n",
    "\n",
    "print(f\"The Accuracy is: {count/200}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "[[0.99900496]]\n"
     ]
    }
   ],
   "source": [
    "tester = model.predict(np.array([[0.72,1,0,1,1]]))\n",
    "print(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "4.6157794e-07\n"
     ]
    }
   ],
   "source": [
    "# testing the use of weights without training in a new model, this will be used in api, to make process faster\n",
    "\n",
    "weights_1 = model.get_layer('layer1').get_weights()\n",
    "weights_2 = model.get_layer('layer2').get_weights()\n",
    "weights_3 = model.get_layer('layer3').get_weights()\n",
    "\n",
    "new_model = Sequential([\n",
    "    Dense(10, activation= 'relu', name = 'layer1', input_shape=(5,)),\n",
    "    Dense(5, activation= 'relu', name = 'layer2'),\n",
    "    Dense(1, activation='sigmoid', name = 'layer3')\n",
    "])\n",
    "\n",
    "new_model.get_layer('layer1').set_weights(weights_1)\n",
    "new_model.get_layer('layer2').set_weights(weights_2)\n",
    "new_model.get_layer('layer3').set_weights(weights_3)\n",
    "\n",
    "tester = new_model.predict(np.array([[0.42,1,0,1,1]]))\n",
    "print(tester.reshape(-1)[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
